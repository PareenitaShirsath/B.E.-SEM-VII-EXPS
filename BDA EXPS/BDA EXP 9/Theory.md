Experiment: Linear Regression
Aim

To implement and understand the concept of Linear Regression, a fundamental supervised machine learning algorithm used for predicting continuous outcomes based on input variables.

Theory
Introduction

Linear Regression is one of the simplest and most widely used algorithms in machine learning.
It models the relationship between a dependent variable (y) and one or more independent variables (X) using a straight line.

The equation of a simple linear regression line is given by:

ğ‘¦
=
ğ‘š
ğ‘‹
+
ğ‘
y=mX+b

Where:

y â†’ Predicted output (dependent variable)

X â†’ Input or independent variable

m â†’ Slope or coefficient of the line

b â†’ Intercept (value of y when X = 0)

Working Principle

The algorithm tries to find the best-fitting line that minimizes the difference between the actual and predicted values.

This difference is measured using the Mean Squared Error (MSE).

The slope (m) and intercept (b) are calculated using the Least Squares Method, which minimizes the sum of squared residuals.

Mathematical Formulation

For a dataset with 
ğ‘›
n points 
(
ğ‘¥
ğ‘–
,
ğ‘¦
ğ‘–
)
(x
i
	â€‹

,y
i
	â€‹

):

ğ‘š
=
ğ‘›
(
âˆ‘
ğ‘¥
ğ‘¦
)
âˆ’
(
âˆ‘
ğ‘¥
)
(
âˆ‘
ğ‘¦
)
ğ‘›
(
âˆ‘
ğ‘¥
2
)
âˆ’
(
âˆ‘
ğ‘¥
)
2
m=
n(âˆ‘x
2
)âˆ’(âˆ‘x)
2
n(âˆ‘xy)âˆ’(âˆ‘x)(âˆ‘y)
	â€‹

ğ‘
=
(
âˆ‘
ğ‘¦
)
âˆ’
ğ‘š
(
âˆ‘
ğ‘¥
)
ğ‘›
b=
n
(âˆ‘y)âˆ’m(âˆ‘x)
	â€‹

Advantages

Simple to understand and implement.

Computationally efficient.

Provides good interpretability of model coefficients.

Useful as a baseline model for regression problems.

Disadvantages

Assumes a linear relationship between variables.

Sensitive to outliers, which can distort results.

Not suitable for non-linear data.

Performance degrades when there is multicollinearity among features.

Conclusion

Linear Regression helps in understanding relationships between variables and predicting numerical outcomes.
It provides the foundation for more advanced regression and machine learning models.
In this experiment, the slope and intercept obtained were:

SlopeÂ (m)
=
0.3167
,
InterceptÂ (b)
=
4.2
SlopeÂ (m)=0.3167,InterceptÂ (b)=4.2

Hence, the final regression equation is:

ğ‘¦
^
=
0.3167
ğ‘‹
+
4.2
y
^
	â€‹

=0.3167X+4.2
