{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PAREENITA A.SHIRSATH         ROLL.NO : 57 B.E.A.I.&.D.S.\n",
        "\n",
        "\n",
        "NLP EXPERIMENT NO : 09"
      ],
      "metadata": {
        "id": "amDoG_IivU8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "documents = [\n",
        "    \"India has some of the most spectacular and unforgettable rail journeys in the world.\",\n",
        "    \"Here you experience a simple way to find out everything you need to know in one easy place\",\n",
        "    \"There's no better way to enjoy India's outback, cities, coastal towns and regional areas in comfort.\"\n",
        "]\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "\n",
        "cosine_similarities = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "\n",
        "for i, doc1 in enumerate(documents):\n",
        "    for j, doc2 in enumerate(documents):\n",
        "        if i < j:\n",
        "            print(f\"Similarity:- {cosine_similarities[i, j]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjHz-4m_vVER",
        "outputId": "39c6b9cc-1be7-40a6-adb2-f0178560635e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity:- 0.02\n",
            "Similarity:- 0.11\n",
            "Similarity:- 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize stemmer and stopwords list\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    tokens = text.split()  # Tokenization\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]  # Remove stopwords and stem\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Take multiple documents as input\n",
        "num_documents = int(input(\"Enter the number of documents: \"))\n",
        "documents = []\n",
        "\n",
        "for i in range(num_documents):\n",
        "    doc_text = input(f\"Enter text for Document {i+1}: \")\n",
        "    documents.append(doc_text)\n",
        "\n",
        "# Preprocess documents\n",
        "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
        "\n",
        "# Print preprocessed documents for debugging\n",
        "print(\"\\nPreprocessed Documents:\")\n",
        "for idx, doc in enumerate(preprocessed_documents, 1):\n",
        "    print(f\"Document {idx}: {doc}\")\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(preprocessed_documents)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Print all cosine similarities for debugging\n",
        "print(\"\\nCosine Similarity Matrix:\")\n",
        "for i in range(len(documents)):\n",
        "    for j in range(i + 1, len(documents)):\n",
        "        print(f\"Cosine Similarity between Document {i+1} and Document {j+1}: {cosine_similarities[i][j]:.2f}\")\n",
        "\n",
        "# Print pairs of documents that are similar above the threshold\n",
        "print(\"\\nSimilar Document Pairs:\")\n",
        "similarity_threshold = 0.4  # Lower the threshold to capture more similarities\n",
        "similar_pairs = []\n",
        "\n",
        "for i in range(len(documents)):\n",
        "    for j in range(i + 1, len(documents)):\n",
        "        if cosine_similarities[i][j] >= similarity_threshold:\n",
        "            similar_pairs.append((i, j, cosine_similarities[i][j]))\n",
        "\n",
        "if len(similar_pairs) == 0:\n",
        "    print(\"No similar documents found above the threshold.\")\n",
        "else:\n",
        "    for pair in similar_pairs:\n",
        "        doc1, doc2, similarity = pair\n",
        "        print(f\"Document {doc1 + 1} and Document {doc2 + 1} are similar (Cosine Similarity: {similarity:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hoWwxnCv4sj",
        "outputId": "76795644-50e6-40fd-937a-f655e4d690ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of documents: 3\n",
            "Enter text for Document 1: THIS IS MY FIRST REPORT\n",
            "Enter text for Document 2: THIS IS MY SECOND REPORT\n",
            "Enter text for Document 3: THIS IS MY THIRD REPORT\n",
            "\n",
            "Preprocessed Documents:\n",
            "Document 1: first report\n",
            "Document 2: second report\n",
            "Document 3: third report\n",
            "\n",
            "Cosine Similarity Matrix:\n",
            "Cosine Similarity between Document 1 and Document 2: 0.26\n",
            "Cosine Similarity between Document 1 and Document 3: 0.26\n",
            "Cosine Similarity between Document 2 and Document 3: 0.26\n",
            "\n",
            "Similar Document Pairs:\n",
            "No similar documents found above the threshold.\n"
          ]
        }
      ]
    }
  ]
}