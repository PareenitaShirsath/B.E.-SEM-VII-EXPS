{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NAME : PAREENITA A.SHIRSATH\n",
        "\n",
        "B.E.A.I.&.D.S.     ROLL NO : 57\n",
        "\n",
        "PRN : 221101062\n",
        "\n",
        "NLP EXPERIMENT NO : 3"
      ],
      "metadata": {
        "id": "RQ1sFsNMuGYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = {\n",
        "    'en': \"Natural language processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans through natural language.\",\n",
        "    'hi': \"प्राकृतिक भाषा प्रसंस्करण (NLP) कृत्रिम बुद्धिमत्ता की एक शाखा है जो कंप्यूटर और मनुष्यों के बीच प्राकृतिक भाषा के माध्यम से संवाद पर केंद्रित है।\",\n",
        "    'mr': \"नैसर्गिक भाषा प्रक्रिया (NLP) कृत्रिम बुद्धिमत्तेची एक उपशाखा आहे जी संगणक आणि मानव यांच्यात नैसर्गिक भाषेच्या माध्यमातून संवादावर लक्ष केंद्रित करते.\",\n",
        "    'sa': \"प्राकृतिक भाषा प्रसंस्करण (NLP) कृत्रिम बुद्धिमत्तायाः एकः उपविभागः अस्ति यः संगणकस्य च मानवस्य च मध्ये प्राकृतिक भाषायाः माध्यमेन संवादे केन्द्रितः अस्ति।\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "f9-UsZ1puXSB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv3sv5stuajx",
        "outputId": "c4c14e34-41b3-4187-824d-2f8373631ef6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        ""
      ],
      "metadata": {
        "id": "Fl0ugMOWu5VJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5bQQ-HSvWva",
        "outputId": "a54c5c84-ab42-45b4-f3e7-5d8e1df8b8ee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the values of the 'texts' dictionary and tokenize each string\n",
        "tokenized_texts = {}\n",
        "for lang, text in texts.items():\n",
        "  tokenized_texts[lang] = word_tokenize(text)\n",
        "\n",
        "# Print the tokens for each language\n",
        "for lang, tokens in tokenized_texts.items():\n",
        "  print(f\"Original Tokens ({lang}):\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAusywubviER",
        "outputId": "5be5d8cd-105e-471d-9393-e7599efd8505"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens (en): ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language', '.']\n",
            "Original Tokens (hi): ['प्राकृतिक', 'भाषा', 'प्रसंस्करण', '(', 'NLP', ')', 'कृत्रिम', 'बुद्धिमत्ता', 'की', 'एक', 'शाखा', 'है', 'जो', 'कंप्यूटर', 'और', 'मनुष्यों', 'के', 'बीच', 'प्राकृतिक', 'भाषा', 'के', 'माध्यम', 'से', 'संवाद', 'पर', 'केंद्रित', 'है।']\n",
            "Original Tokens (mr): ['नैसर्गिक', 'भाषा', 'प्रक्रिया', '(', 'NLP', ')', 'कृत्रिम', 'बुद्धिमत्तेची', 'एक', 'उपशाखा', 'आहे', 'जी', 'संगणक', 'आणि', 'मानव', 'यांच्यात', 'नैसर्गिक', 'भाषेच्या', 'माध्यमातून', 'संवादावर', 'लक्ष', 'केंद्रित', 'करते', '.']\n",
            "Original Tokens (sa): ['प्राकृतिक', 'भाषा', 'प्रसंस्करण', '(', 'NLP', ')', 'कृत्रिम', 'बुद्धिमत्तायाः', 'एकः', 'उपविभागः', 'अस्ति', 'यः', 'संगणकस्य', 'च', 'मानवस्य', 'च', 'मध्ये', 'प्राकृतिक', 'भाषायाः', 'माध्यमेन', 'संवादे', 'केन्द्रितः', 'अस्ति।']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(\"Filtered Tokens (Stop Words Removed):-\", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB4c3e08wJ95",
        "outputId": "b72ac4cb-f1f7-45a9-97e9-37492ea8214e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Tokens (Stop Words Removed):- ['प्राकृतिक', 'भाषा', 'प्रसंस्करण', '(', 'NLP', ')', 'कृत्रिम', 'बुद्धिमत्तायाः', 'एकः', 'उपविभागः', 'अस्ति', 'यः', 'संगणकस्य', 'च', 'मानवस्य', 'च', 'मध्ये', 'प्राकृतिक', 'भाषायाः', 'माध्यमेन', 'संवादे', 'केन्द्रितः', 'अस्ति।']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(\"Stemmed Tokens:-\", stemmed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzps_XLEwOnp",
        "outputId": "69de37ea-3361-4715-8ad1-1ff2e6227654"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Tokens:- ['प्राकृतिक', 'भाषा', 'प्रसंस्करण', '(', 'nlp', ')', 'कृत्रिम', 'बुद्धिमत्तायाः', 'एकः', 'उपविभागः', 'अस्ति', 'यः', 'संगणकस्य', 'च', 'मानवस्य', 'च', 'मध्ये', 'प्राकृतिक', 'भाषायाः', 'माध्यमेन', 'संवादे', 'केन्द्रितः', 'अस्ति।']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(\"Lemmatized Tokens:-\", lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNw3g4x7wSex",
        "outputId": "5176b595-da11-4ba4-e320-6f0848a64257"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Tokens:- ['प्राकृतिक', 'भाषा', 'प्रसंस्करण', '(', 'NLP', ')', 'कृत्रिम', 'बुद्धिमत्तायाः', 'एकः', 'उपविभागः', 'अस्ति', 'यः', 'संगणकस्य', 'च', 'मानवस्य', 'च', 'मध्ये', 'प्राकृतिक', 'भाषायाः', 'माध्यमेन', 'संवादे', 'केन्द्रितः', 'अस्ति।']\n"
          ]
        }
      ]
    }
  ]
}